{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27073,
     "status": "ok",
     "timestamp": 1706799050592,
     "user": {
      "displayName": "samuele ghezzo",
      "userId": "15082388614660204669"
     },
     "user_tz": -60
    },
    "id": "4oUSMF5Wklyj",
    "outputId": "a947c53f-3bd5-4733-cadd-21362ed2a89b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn import metrics\n",
    "import openpyxl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/osr_rdx_suv_aftercombat_ScannerHarmonization.csv'\n",
    "df_step1 = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare features and target\n",
    "X1 = df_step1[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y1 = df_step1['outcome'].values\n",
    "\n",
    "# Initialize models and preprocessing steps\n",
    "scaler = StandardScaler()\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "randomforest = RandomForestClassifier()\n",
    "svm = SVC(probability=True)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Create pipelines\n",
    "pipeline_rf = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_rf\", randomforest)])\n",
    "pipeline_svm = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_svm\", svm)])\n",
    "pipeline_lr = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_lr\", lr)])\n",
    "\n",
    "# Define hyperparameter grids\n",
    "rf_params = {'model_rf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "             'model_rf__min_samples_split': [2, 3],\n",
    "             'model_rf__min_samples_leaf': [1, 2],\n",
    "             'model_rf__max_features': [2]}\n",
    "\n",
    "svm_params = {'model_svm__C': [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "              'model_svm__gamma': [0.5, 0.8, 1, 1.5],\n",
    "              'model_svm__kernel': ['linear'],\n",
    "              'model_svm__probability': [True]}\n",
    "\n",
    "lr_params = {'model_lr__solver': ['lbfgs', 'newton-cg', 'liblinear'],\n",
    "             'model_lr__penalty': ['l2'],\n",
    "             'model_lr__C': [0.1, 0.5, 0.8, 1, 1.25, 2]}\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "num_zeros_list, num_ones_list = [], []\n",
    "rf_train_metrics_list, svm_train_metrics_list, lr_train_metrics_list = [], [], []\n",
    "rf_metrics_list, svm_metrics_list, lr_metrics_list, majority_metrics_list = [], [], [], []\n",
    "rf_all_fpr, rf_all_tpr, svm_all_fpr, svm_all_tpr, lr_all_fpr, lr_all_tpr, majority_all_fpr, majority_all_tpr = [], [], [], [], [], [], [], []\n",
    "\n",
    "# Loop over iterations\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, stratify=y1, random_state=i)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Resample training data\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Grid search for each model\n",
    "    rf_gs = GridSearchCV(pipeline_rf, rf_params, scoring='roc_auc')\n",
    "    svm_gs = GridSearchCV(pipeline_svm, svm_params, scoring='roc_auc')\n",
    "    lr_gs = GridSearchCV(pipeline_lr, lr_params, scoring='roc_auc')\n",
    "\n",
    "    rf_gs.fit(X_train_scaled, y_train)\n",
    "    svm_gs.fit(X_train_scaled, y_train)\n",
    "    lr_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Training AUC and hyperparameters\n",
    "    rf_train_auc = rf_gs.best_score_\n",
    "    rf_train_metrics_list.append({'AUC': rf_train_auc, 'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_train_auc = svm_gs.best_score_\n",
    "    svm_train_metrics_list.append({'AUC': svm_train_auc, 'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_train_auc = lr_gs.best_score_\n",
    "    lr_train_metrics_list.append({'AUC': lr_train_auc, 'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    rf_pred = rf_gs.predict(X_test_scaled)\n",
    "    svm_pred = svm_gs.predict(X_test_scaled)\n",
    "    lr_pred = lr_gs.predict(X_test_scaled)\n",
    "\n",
    "    rf_proba = rf_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    svm_proba = svm_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    lr_proba = lr_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Test set metrics for each model\n",
    "    rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "    svm_auc = roc_auc_score(y_test, svm_proba)\n",
    "    lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "    rf_metrics_list.append({'AUC': rf_auc, 'Accuracy': accuracy_score(y_test, rf_pred), 'Sensitivity': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_metrics_list.append({'AUC': svm_auc, 'Accuracy': accuracy_score(y_test, svm_pred), 'Sensitivity': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Specificity': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'PPV': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'NPV': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_metrics_list.append({'AUC': lr_auc, 'Accuracy': accuracy_score(y_test, lr_pred), 'Sensitivity': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # ROC curve for each model\n",
    "    rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba, drop_intermediate=False)\n",
    "    interp_rf_tpr = np.interp(np.linspace(0, 1, 100), rf_fpr, rf_tpr)\n",
    "    rf_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    rf_all_tpr.append(interp_rf_tpr)\n",
    "\n",
    "    svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_proba, drop_intermediate=False)\n",
    "    interp_svm_tpr = np.interp(np.linspace(0, 1, 100), svm_fpr, svm_tpr)\n",
    "    svm_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    svm_all_tpr.append(interp_svm_tpr)\n",
    "\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_proba, drop_intermediate=False)\n",
    "    interp_lr_tpr = np.interp(np.linspace(0, 1, 100), lr_fpr, lr_tpr)\n",
    "    lr_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    lr_all_tpr.append(interp_lr_tpr)\n",
    "\n",
    "    # Majority Vote model\n",
    "    clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(**{key.split('__')[1]: value for key, value in rf_gs.best_params_.items()})),\n",
    "    ('svm', SVC(**{key.split('__')[1]: value for key, value in svm_gs.best_params_.items()})),\n",
    "    ('lr', LogisticRegression(**{key.split('__')[1]: value for key, value in lr_gs.best_params_.items()}))\n",
    "    ], voting='soft', flatten_transform=True)\n",
    "\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Majority Vote metrics\n",
    "    majority_auc = roc_auc_score(y_test, y_proba)\n",
    "    majority_cm = confusion_matrix(y_test, y_pred)\n",
    "    majority_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    majority_sensitivity = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[1, 0])\n",
    "    majority_specificity = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[0, 1])\n",
    "    majority_ppv = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[0, 1])\n",
    "    majority_npv = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[1, 0])\n",
    "\n",
    "    majority_metrics_list.append({'AUC': majority_auc, 'Accuracy': majority_accuracy,\n",
    "                                  'Sensitivity': majority_sensitivity, 'Specificity': majority_specificity,\n",
    "                                  'PPV': majority_ppv, 'NPV': majority_npv})\n",
    "\n",
    "    majority_fpr, majority_tpr, _ = roc_curve(y_test, y_proba, drop_intermediate=False)\n",
    "    interp_majority_tpr = np.interp(np.linspace(0, 1, 100), majority_fpr, majority_tpr)\n",
    "    majority_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    majority_all_tpr.append(interp_majority_tpr)\n",
    "\n",
    "    # Store class distribution in each iteration\n",
    "    num_zeros_list.append(np.sum(y_test == 0))\n",
    "    num_ones_list.append(np.sum(y_test == 1))\n",
    "\n",
    "# Create DataFrames for metrics\n",
    "rf_train_metrics_df = pd.DataFrame(rf_train_metrics_list)\n",
    "svm_train_metrics_df = pd.DataFrame(svm_train_metrics_list)\n",
    "lr_train_metrics_df = pd.DataFrame(lr_train_metrics_list)\n",
    "\n",
    "rf_metrics_df_soft = pd.DataFrame(rf_metrics_list)\n",
    "svm_metrics_df_soft = pd.DataFrame(svm_metrics_list)\n",
    "lr_metrics_df_soft = pd.DataFrame(lr_metrics_list)\n",
    "majority_metrics_df_soft = pd.DataFrame(majority_metrics_list)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "rf_mean_fpr = np.mean(rf_all_fpr, axis=0)\n",
    "rf_mean_tpr = np.mean(rf_all_tpr, axis=0)\n",
    "plt.plot(rf_mean_fpr, rf_mean_tpr, label=f'Random Forest AUC = {np.mean(rf_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "\n",
    "svm_mean_fpr = np.mean(svm_all_fpr, axis=0)\n",
    "svm_mean_tpr = np.mean(svm_all_tpr, axis=0)\n",
    "plt.plot(svm_mean_fpr, svm_mean_tpr, label=f'SVM AUC = {np.mean(svm_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "lr_mean_fpr = np.mean(lr_all_fpr, axis=0)\n",
    "lr_mean_tpr = np.mean(lr_all_tpr, axis=0)\n",
    "lr_mean_fpr = np.concatenate([[0], lr_mean_fpr])\n",
    "lr_mean_tpr = np.concatenate([[0], lr_mean_tpr])\n",
    "plt.plot(lr_mean_fpr, lr_mean_tpr, label=f'Logistic Regression AUC = {np.mean(lr_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "majority_mean_fpr = np.mean(majority_all_fpr, axis=0)\n",
    "majority_mean_tpr = np.mean(majority_all_tpr, axis=0)\n",
    "majority_mean_fpr = np.concatenate([[0], majority_mean_fpr])\n",
    "majority_mean_tpr = np.concatenate([[0], majority_mean_tpr])\n",
    "plt.plot(majority_mean_fpr, majority_mean_tpr, label=f'Majority Vote AUC = {np.mean(majority_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for class distribution\n",
    "sanity_check_df = pd.DataFrame({'Num_Zeros': num_zeros_list, 'Num_Ones': num_ones_list})\n",
    "\n",
    "# Print average AUC values for each model in both training and test sets\n",
    "print(f'The average AUC for Random Forest in the training set is: {rf_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the training set is: {svm_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the training set is: {lr_train_metrics_df[\"AUC\"].mean()}')\n",
    "print()\n",
    "print(f'The average AUC for Random Forest in the test set is: {rf_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the test set is: {svm_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the test set is: {lr_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for the Majority Vote model in the test set is: {majority_metrics_df_soft[\"AUC\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_train_results_rf.xlsx')\n",
    "svm_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_train_results_svm.xlsx')\n",
    "lr_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_train_results_lr.xlsx')\n",
    "\n",
    "rf_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_results_rf.xlsx')\n",
    "svm_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_results_svm.xlsx')\n",
    "lr_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_results_lr.xlsx')\n",
    "majority_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP1_results_majority.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/stn_rdx_rp.xlsx'\n",
    "df_step2 = pd.read_excel(file_path)\n",
    "file_path_outcome = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_radiomics/DB_STN_PET_RP.xlsx'\n",
    "df_step2_outcome = pd.read_excel(file_path_outcome)\n",
    "df_step2complete = pd.merge(df_step2, df_step2_outcome, on='ID')\n",
    "\n",
    "# Prepare features and target\n",
    "X2 = df_step2complete[['original_glszm_ZoneEntropy', 'original_shape_LeastAxisLength']].values\n",
    "y2 = df_step2complete['ISUP_binary'].values\n",
    "\n",
    "# Initialize models and preprocessing steps\n",
    "scaler = StandardScaler()\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "randomforest = RandomForestClassifier()\n",
    "svm = SVC(probability=True)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Create pipelines\n",
    "pipeline_rf = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_rf\", randomforest)])\n",
    "pipeline_svm = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_svm\", svm)])\n",
    "pipeline_lr = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_lr\", lr)])\n",
    "\n",
    "# Define hyperparameter grids\n",
    "rf_params = {'model_rf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "             'model_rf__min_samples_split': [2, 3],\n",
    "             'model_rf__min_samples_leaf': [1, 2],\n",
    "             'model_rf__max_features': [2]}\n",
    "\n",
    "svm_params = {'model_svm__C': [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "              'model_svm__gamma': [0.5, 0.8, 1, 1.5],\n",
    "              'model_svm__kernel': ['linear'],\n",
    "              'model_svm__probability': [True]}\n",
    "\n",
    "lr_params = {'model_lr__solver': ['lbfgs', 'newton-cg', 'liblinear'],\n",
    "             'model_lr__penalty': ['l2'],\n",
    "             'model_lr__C': [0.1, 0.5, 0.8, 1, 1.25, 2]}\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "num_zeros_list, num_ones_list = [], []\n",
    "rf_train_metrics_list, svm_train_metrics_list, lr_train_metrics_list = [], [], []\n",
    "rf_metrics_list, svm_metrics_list, lr_metrics_list, majority_metrics_list = [], [], [], []\n",
    "rf_all_fpr, rf_all_tpr, svm_all_fpr, svm_all_tpr, lr_all_fpr, lr_all_tpr, majority_all_fpr, majority_all_tpr = [], [], [], [], [], [], [], []\n",
    "\n",
    "# Loop over iterations\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.3, stratify=y2, random_state=i)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Resample training data\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Grid search for each model\n",
    "    rf_gs = GridSearchCV(pipeline_rf, rf_params, scoring='roc_auc')\n",
    "    svm_gs = GridSearchCV(pipeline_svm, svm_params, scoring='roc_auc')\n",
    "    lr_gs = GridSearchCV(pipeline_lr, lr_params, scoring='roc_auc')\n",
    "\n",
    "    rf_gs.fit(X_train_scaled, y_train)\n",
    "    svm_gs.fit(X_train_scaled, y_train)\n",
    "    lr_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Training AUC and hyperparameters\n",
    "    rf_train_auc = rf_gs.best_score_\n",
    "    rf_train_metrics_list.append({'AUC': rf_train_auc, 'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_train_auc = svm_gs.best_score_\n",
    "    svm_train_metrics_list.append({'AUC': svm_train_auc, 'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_train_auc = lr_gs.best_score_\n",
    "    lr_train_metrics_list.append({'AUC': lr_train_auc, 'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    rf_pred = rf_gs.predict(X_test_scaled)\n",
    "    svm_pred = svm_gs.predict(X_test_scaled)\n",
    "    lr_pred = lr_gs.predict(X_test_scaled)\n",
    "\n",
    "    rf_proba = rf_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    svm_proba = svm_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    lr_proba = lr_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Test set metrics for each model\n",
    "    rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "    svm_auc = roc_auc_score(y_test, svm_proba)\n",
    "    lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "    rf_metrics_list.append({'AUC': rf_auc, 'Accuracy': accuracy_score(y_test, rf_pred), 'Sensitivity': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_metrics_list.append({'AUC': svm_auc, 'Accuracy': accuracy_score(y_test, svm_pred), 'Sensitivity': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Specificity': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'PPV': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'NPV': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_metrics_list.append({'AUC': lr_auc, 'Accuracy': accuracy_score(y_test, lr_pred), 'Sensitivity': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # ROC curve for each model\n",
    "    rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba, drop_intermediate=False)\n",
    "    interp_rf_tpr = np.interp(np.linspace(0, 1, 100), rf_fpr, rf_tpr)\n",
    "    rf_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    rf_all_tpr.append(interp_rf_tpr)\n",
    "\n",
    "    svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_proba, drop_intermediate=False)\n",
    "    interp_svm_tpr = np.interp(np.linspace(0, 1, 100), svm_fpr, svm_tpr)\n",
    "    svm_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    svm_all_tpr.append(interp_svm_tpr)\n",
    "\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_proba, drop_intermediate=False)\n",
    "    interp_lr_tpr = np.interp(np.linspace(0, 1, 100), lr_fpr, lr_tpr)\n",
    "    lr_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    lr_all_tpr.append(interp_lr_tpr)\n",
    "\n",
    "    # Majority Vote model\n",
    "    clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(**{key.split('__')[1]: value for key, value in rf_gs.best_params_.items()})),\n",
    "    ('svm', SVC(**{key.split('__')[1]: value for key, value in svm_gs.best_params_.items()})),\n",
    "    ('lr', LogisticRegression(**{key.split('__')[1]: value for key, value in lr_gs.best_params_.items()}))\n",
    "    ], voting='soft', flatten_transform=True)\n",
    "\n",
    "\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Majority Vote metrics\n",
    "    majority_auc = roc_auc_score(y_test, y_proba)\n",
    "    majority_cm = confusion_matrix(y_test, y_pred)\n",
    "    majority_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    majority_sensitivity = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[1, 0])\n",
    "    majority_specificity = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[0, 1])\n",
    "    majority_ppv = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[0, 1])\n",
    "    majority_npv = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[1, 0])\n",
    "\n",
    "    majority_metrics_list.append({'AUC': majority_auc, 'Accuracy': majority_accuracy,\n",
    "                                  'Sensitivity': majority_sensitivity, 'Specificity': majority_specificity,\n",
    "                                  'PPV': majority_ppv, 'NPV': majority_npv})\n",
    "\n",
    "    majority_fpr, majority_tpr, _ = roc_curve(y_test, y_proba, drop_intermediate=False)\n",
    "    interp_majority_tpr = np.interp(np.linspace(0, 1, 100), majority_fpr, majority_tpr)\n",
    "    majority_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    majority_all_tpr.append(interp_majority_tpr)\n",
    "\n",
    "    # Store class distribution in each iteration\n",
    "    num_zeros_list.append(np.sum(y_test == 0))\n",
    "    num_ones_list.append(np.sum(y_test == 1))\n",
    "\n",
    "# Create DataFrames for metrics\n",
    "rf_train_metrics_df = pd.DataFrame(rf_train_metrics_list)\n",
    "svm_train_metrics_df = pd.DataFrame(svm_train_metrics_list)\n",
    "lr_train_metrics_df = pd.DataFrame(lr_train_metrics_list)\n",
    "\n",
    "rf_metrics_df_soft = pd.DataFrame(rf_metrics_list)\n",
    "svm_metrics_df_soft = pd.DataFrame(svm_metrics_list)\n",
    "lr_metrics_df_soft = pd.DataFrame(lr_metrics_list)\n",
    "majority_metrics_df_soft = pd.DataFrame(majority_metrics_list)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "rf_mean_fpr = np.mean(rf_all_fpr, axis=0)\n",
    "rf_mean_tpr = np.mean(rf_all_tpr, axis=0)\n",
    "plt.plot(rf_mean_fpr, rf_mean_tpr, label=f'Random Forest AUC = {np.mean(rf_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "\n",
    "svm_mean_fpr = np.mean(svm_all_fpr, axis=0)\n",
    "svm_mean_tpr = np.mean(svm_all_tpr, axis=0)\n",
    "plt.plot(svm_mean_fpr, svm_mean_tpr, label=f'SVM AUC = {np.mean(svm_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "lr_mean_fpr = np.mean(lr_all_fpr, axis=0)\n",
    "lr_mean_tpr = np.mean(lr_all_tpr, axis=0)\n",
    "lr_mean_fpr = np.concatenate([[0], lr_mean_fpr])\n",
    "lr_mean_tpr = np.concatenate([[0], lr_mean_tpr])\n",
    "plt.plot(lr_mean_fpr, lr_mean_tpr, label=f'Logistic Regression AUC = {np.mean(lr_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "majority_mean_fpr = np.mean(majority_all_fpr, axis=0)\n",
    "majority_mean_tpr = np.mean(majority_all_tpr, axis=0)\n",
    "majority_mean_fpr = np.concatenate([[0], majority_mean_fpr])\n",
    "majority_mean_tpr = np.concatenate([[0], majority_mean_tpr])\n",
    "plt.plot(majority_mean_fpr, majority_mean_tpr, label=f'Majority Vote AUC = {np.mean(majority_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for class distribution\n",
    "sanity_check_df = pd.DataFrame({'Num_Zeros': num_zeros_list, 'Num_Ones': num_ones_list})\n",
    "\n",
    "# Print average AUC values for each model in both training and test sets\n",
    "print(f'The average AUC for Random Forest in the training set is: {rf_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the training set is: {svm_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the training set is: {lr_train_metrics_df[\"AUC\"].mean()}')\n",
    "print()\n",
    "print(f'The average AUC for Random Forest in the test set is: {rf_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the test set is: {svm_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the test set is: {lr_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for the Majority Vote model in the test set is: {majority_metrics_df_soft[\"AUC\"].mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_train_results_rf.xlsx')\n",
    "svm_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_train_results_svm.xlsx')\n",
    "lr_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_train_results_lr.xlsx')\n",
    "\n",
    "rf_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_results_rf.xlsx')\n",
    "svm_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_results_svm.xlsx')\n",
    "lr_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_results_lr.xlsx')\n",
    "majority_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP2_results_majority.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DeLong test\n",
    "\n",
    "def delong_test(y_true, y_score1, y_score2):\n",
    "    n = len(y_true)\n",
    "    auc1 = roc_auc_score(y_true, y_score1)\n",
    "    auc2 = roc_auc_score(y_true, y_score2)\n",
    "    u_stat, p_value = wilcoxon(x=y_score1, y=y_score2)\n",
    "    return u_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/df_step3_4_5.csv'\n",
    "df_step3 = pd.read_csv(file_path)\n",
    "df_train_step3 = df_step3.iloc[0:62,]\n",
    "df_test_step3 =df_step3.iloc[62:,]\n",
    "\n",
    "X_train = df_train_step3[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y_train = df_train_step3['x'].values\n",
    "X_test = df_test_step3[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y_test = df_test_step3['x'].values\n",
    "\n",
    "# Initialize models and preprocessing steps\n",
    "scaler = StandardScaler()\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "randomforest = RandomForestClassifier()\n",
    "svm = SVC(probability=True)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Create pipelines\n",
    "pipeline_rf = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_rf\", randomforest)])\n",
    "pipeline_svm = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_svm\", svm)])\n",
    "pipeline_lr = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_lr\", lr)])\n",
    "\n",
    "# Define hyperparameter grids\n",
    "rf_params = {'model_rf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "             'model_rf__min_samples_split': [2, 3],\n",
    "             'model_rf__min_samples_leaf': [1, 2],\n",
    "             'model_rf__max_features': [2]}\n",
    "\n",
    "svm_params = {'model_svm__C': [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "              'model_svm__gamma': [0.5, 0.8, 1, 1.5],\n",
    "              'model_svm__kernel': ['linear'],\n",
    "              'model_svm__probability': [True]}\n",
    "\n",
    "lr_params = {'model_lr__solver': ['lbfgs', 'newton-cg', 'liblinear'],\n",
    "             'model_lr__penalty': ['l2'],\n",
    "             'model_lr__C': [0.1, 0.5, 0.8, 1, 1.25, 2]}\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "rf_train_metrics_list, svm_train_metrics_list, lr_train_metrics_list = [], [], []\n",
    "rf_metrics_list, svm_metrics_list, lr_metrics_list, majority_metrics_list = [], [], [], []\n",
    "    \n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "# Resample training data\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Grid search for each model\n",
    "rf_gs = GridSearchCV(pipeline_rf, rf_params, scoring='roc_auc')\n",
    "svm_gs = GridSearchCV(pipeline_svm, svm_params, scoring='roc_auc')\n",
    "lr_gs = GridSearchCV(pipeline_lr, lr_params, scoring='roc_auc')\n",
    "\n",
    "rf_gs.fit(X_train_scaled, y_train)\n",
    "svm_gs.fit(X_train_scaled, y_train)\n",
    "lr_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Training AUC and hyperparameters\n",
    "rf_train_auc = rf_gs.best_score_\n",
    "rf_train_metrics_list.append({'AUC': rf_train_auc, 'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "svm_train_auc = svm_gs.best_score_\n",
    "svm_train_metrics_list.append({'AUC': svm_train_auc, 'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "lr_train_auc = lr_gs.best_score_\n",
    "lr_train_metrics_list.append({'AUC': lr_train_auc, 'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "# Predictions and probabilities\n",
    "rf_pred = rf_gs.predict(X_test_scaled)\n",
    "svm_pred = svm_gs.predict(X_test_scaled)\n",
    "lr_pred = lr_gs.predict(X_test_scaled)\n",
    "\n",
    "rf_proba = rf_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "svm_proba = svm_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_proba = lr_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Test set metrics for each model\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "svm_auc = roc_auc_score(y_test, svm_proba)\n",
    "lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "rf_metrics_list.append({'AUC': rf_auc, 'Accuracy': accuracy_score(y_test, rf_pred), 'Sensitivity': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "svm_metrics_list.append({'AUC': svm_auc, 'Accuracy': accuracy_score(y_test, svm_pred), 'Sensitivity': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Specificity': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'PPV': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'NPV': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "lr_metrics_list.append({'AUC': lr_auc, 'Accuracy': accuracy_score(y_test, lr_pred), 'Sensitivity': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "# ROC curve for each model\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba, drop_intermediate=False)\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_proba, drop_intermediate=False)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_proba, drop_intermediate=False)\n",
    "\n",
    "\n",
    "# Majority Vote model\n",
    "clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(**{key.split('__')[1]: value for key, value in rf_gs.best_params_.items()})),\n",
    "    ('svm', SVC(**{key.split('__')[1]: value for key, value in svm_gs.best_params_.items()})),\n",
    "    ('lr', LogisticRegression(**{key.split('__')[1]: value for key, value in lr_gs.best_params_.items()}))\n",
    "], voting='soft', flatten_transform=True)\n",
    "\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Majority Vote metrics\n",
    "majority_auc = roc_auc_score(y_test, y_proba)\n",
    "majority_cm = confusion_matrix(y_test, y_pred)\n",
    "majority_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "majority_sensitivity = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[1, 0])\n",
    "majority_specificity = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[0, 1])\n",
    "majority_ppv = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[0, 1])\n",
    "majority_npv = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[1, 0])\n",
    "\n",
    "majority_metrics_list.append({'AUC': majority_auc, 'Accuracy': majority_accuracy,\n",
    "                                  'Sensitivity': majority_sensitivity, 'Specificity': majority_specificity,\n",
    "                                  'PPV': majority_ppv, 'NPV': majority_npv})\n",
    "\n",
    "majority_fpr, majority_tpr, _ = roc_curve(y_test, y_proba, drop_intermediate=False)\n",
    "\n",
    "# Create DataFrames for metrics\n",
    "rf_train_metrics_df = pd.DataFrame(rf_train_metrics_list)\n",
    "svm_train_metrics_df = pd.DataFrame(svm_train_metrics_list)\n",
    "lr_train_metrics_df = pd.DataFrame(lr_train_metrics_list)\n",
    "\n",
    "rf_metrics_df_soft = pd.DataFrame(rf_metrics_list)\n",
    "svm_metrics_df_soft = pd.DataFrame(svm_metrics_list)\n",
    "lr_metrics_df_soft = pd.DataFrame(lr_metrics_list)\n",
    "majority_metrics_df_soft = pd.DataFrame(majority_metrics_list)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest AUC = {rf_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(svm_fpr, svm_tpr, label=f'SVM AUC = {svm_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression AUC = {lr_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(majority_fpr, majority_tpr, label=f'Majority Vote AUC = {majority_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print average AUC values for each model in both training and test sets\n",
    "print(f'The average AUC for Random Forest in the training set is: {rf_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the training set is: {svm_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the training set is: {lr_train_metrics_df[\"AUC\"].mean()}')\n",
    "print()\n",
    "print(f'The AUC for Random Forest in the test set is: {rf_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for SVM in the test set is: {svm_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for Logistic Regression in the test set is: {lr_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for the Majority Vote model in the test set is: {majority_metrics_df_soft[\"AUC\"].mean()}')\n",
    "\n",
    "# De Long test\n",
    "a, delong_p_lr_mv = delong_test(y_test, lr_proba, y_proba)\n",
    "b, delong_p_lr_rf = delong_test(y_test, lr_proba, rf_proba)\n",
    "c, delong_p_lr_svm = delong_test(y_test, lr_proba, svm_proba)\n",
    "d, delong_p_mv_rf = delong_test(y_test, y_proba, rf_proba)\n",
    "e, delong_p_mv_svm = delong_test(y_test, y_proba, svm_proba)\n",
    "f, delong_p_rf_svm = delong_test(y_test, rf_proba, svm_proba)\n",
    "\n",
    "print(f\"{delong_p_lr_mv}, {delong_p_lr_rf}, {delong_p_lr_svm}, {delong_p_mv_rf}, {delong_p_mv_svm}, {delong_p_rf_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_train_results_rf.xlsx')\n",
    "svm_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_train_results_svm.xlsx')\n",
    "lr_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_train_results_lr.xlsx')\n",
    "\n",
    "rf_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_results_rf.xlsx')\n",
    "svm_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_results_svm.xlsx')\n",
    "lr_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_results_lr.xlsx')\n",
    "majority_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP3_results_majority.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/df_step3_4_5.csv'\n",
    "df_step4 = pd.read_csv(file_path)\n",
    "df_test_step4 = df_step4.iloc[0:62,]\n",
    "df_train_step4 =df_step4.iloc[62:,]\n",
    "\n",
    "X_train = df_train_step4[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y_train = df_train_step4['x'].values\n",
    "X_test = df_test_step4[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y_test = df_test_step4['x'].values\n",
    "\n",
    "# Initialize models and preprocessing steps\n",
    "scaler = StandardScaler()\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "randomforest = RandomForestClassifier()\n",
    "svm = SVC(probability=True)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Create pipelines\n",
    "pipeline_rf = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_rf\", randomforest)])\n",
    "pipeline_svm = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_svm\", svm)])\n",
    "pipeline_lr = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_lr\", lr)])\n",
    "\n",
    "# Define hyperparameter grids\n",
    "rf_params = {'model_rf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "             'model_rf__min_samples_split': [2, 3],\n",
    "             'model_rf__min_samples_leaf': [1, 2],\n",
    "             'model_rf__max_features': [2]}\n",
    "\n",
    "svm_params = {'model_svm__C': [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "              'model_svm__gamma': [0.5, 0.8, 1, 1.5],\n",
    "              'model_svm__kernel': ['linear'],\n",
    "              'model_svm__probability': [True]}\n",
    "\n",
    "lr_params = {'model_lr__solver': ['lbfgs', 'newton-cg', 'liblinear'],\n",
    "             'model_lr__penalty': ['l2'],\n",
    "             'model_lr__C': [0.1, 0.5, 0.8, 1, 1.25, 2]}\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "rf_train_metrics_list, svm_train_metrics_list, lr_train_metrics_list = [], [], []\n",
    "rf_metrics_list, svm_metrics_list, lr_metrics_list, majority_metrics_list = [], [], [], []\n",
    "    \n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "# Resample training data\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Grid search for each model\n",
    "rf_gs = GridSearchCV(pipeline_rf, rf_params, scoring='roc_auc')\n",
    "svm_gs = GridSearchCV(pipeline_svm, svm_params, scoring='roc_auc')\n",
    "lr_gs = GridSearchCV(pipeline_lr, lr_params, scoring='roc_auc')\n",
    "\n",
    "rf_gs.fit(X_train_scaled, y_train)\n",
    "svm_gs.fit(X_train_scaled, y_train)\n",
    "lr_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Training AUC and hyperparameters\n",
    "rf_train_auc = rf_gs.best_score_\n",
    "rf_train_metrics_list.append({'AUC': rf_train_auc, 'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "svm_train_auc = svm_gs.best_score_\n",
    "svm_train_metrics_list.append({'AUC': svm_train_auc, 'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "lr_train_auc = lr_gs.best_score_\n",
    "lr_train_metrics_list.append({'AUC': lr_train_auc, 'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "# Predictions and probabilities\n",
    "rf_pred = rf_gs.predict(X_test_scaled)\n",
    "svm_pred = svm_gs.predict(X_test_scaled)\n",
    "lr_pred = lr_gs.predict(X_test_scaled)\n",
    "\n",
    "rf_proba = rf_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "svm_proba = svm_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_proba = lr_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Test set metrics for each model\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "svm_auc = roc_auc_score(y_test, svm_proba)\n",
    "lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "rf_metrics_list.append({'AUC': rf_auc, 'Accuracy': accuracy_score(y_test, rf_pred), 'Sensitivity': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "svm_metrics_list.append({'AUC': svm_auc, 'Accuracy': accuracy_score(y_test, svm_pred), 'Sensitivity': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Specificity': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'PPV': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'NPV': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "lr_metrics_list.append({'AUC': lr_auc, 'Accuracy': accuracy_score(y_test, lr_pred), 'Sensitivity': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "# ROC curve for each model\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba, drop_intermediate=False)\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_proba, drop_intermediate=False)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_proba, drop_intermediate=False)\n",
    "\n",
    "\n",
    "# Majority Vote model\n",
    "clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(**{key.split('__')[1]: value for key, value in rf_gs.best_params_.items()})),\n",
    "    ('svm', SVC(**{key.split('__')[1]: value for key, value in svm_gs.best_params_.items()})),\n",
    "    ('lr', LogisticRegression(**{key.split('__')[1]: value for key, value in lr_gs.best_params_.items()}))\n",
    "], voting='soft', flatten_transform=True)\n",
    "\n",
    "\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Majority Vote metrics\n",
    "majority_auc = roc_auc_score(y_test, y_proba)\n",
    "majority_cm = confusion_matrix(y_test, y_pred)\n",
    "majority_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "majority_sensitivity = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[1, 0])\n",
    "majority_specificity = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[0, 1])\n",
    "majority_ppv = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[0, 1])\n",
    "majority_npv = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[1, 0])\n",
    "\n",
    "majority_metrics_list.append({'AUC': majority_auc, 'Accuracy': majority_accuracy,\n",
    "                                  'Sensitivity': majority_sensitivity, 'Specificity': majority_specificity,\n",
    "                                  'PPV': majority_ppv, 'NPV': majority_npv})\n",
    "\n",
    "majority_fpr, majority_tpr, _ = roc_curve(y_test, y_proba, drop_intermediate=False)\n",
    "\n",
    "# Create DataFrames for metrics\n",
    "rf_train_metrics_df = pd.DataFrame(rf_train_metrics_list)\n",
    "svm_train_metrics_df = pd.DataFrame(svm_train_metrics_list)\n",
    "lr_train_metrics_df = pd.DataFrame(lr_train_metrics_list)\n",
    "\n",
    "rf_metrics_df_soft = pd.DataFrame(rf_metrics_list)\n",
    "svm_metrics_df_soft = pd.DataFrame(svm_metrics_list)\n",
    "lr_metrics_df_soft = pd.DataFrame(lr_metrics_list)\n",
    "majority_metrics_df_soft = pd.DataFrame(majority_metrics_list)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest AUC = {rf_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(svm_fpr, svm_tpr, label=f'SVM AUC = {svm_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression AUC = {lr_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "plt.plot(majority_fpr, majority_tpr, label=f'Majority Vote AUC = {majority_metrics_df_soft[\"AUC\"].mean():.3f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print average AUC values for each model in both training and test sets\n",
    "print(f'The average AUC for Random Forest in the training set is: {rf_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the training set is: {svm_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the training set is: {lr_train_metrics_df[\"AUC\"].mean()}')\n",
    "print()\n",
    "print(f'The AUC for Random Forest in the test set is: {rf_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for SVM in the test set is: {svm_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for Logistic Regression in the test set is: {lr_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The AUC for the Majority Vote model in the test set is: {majority_metrics_df_soft[\"AUC\"].mean()}')\n",
    "\n",
    "# De Long test\n",
    "a, delong_p_lr_mv = delong_test(y_test, lr_proba, y_proba)\n",
    "b, delong_p_lr_rf = delong_test(y_test, lr_proba, rf_proba)\n",
    "c, delong_p_lr_svm = delong_test(y_test, lr_proba, svm_proba)\n",
    "d, delong_p_mv_rf = delong_test(y_test, y_proba, rf_proba)\n",
    "e, delong_p_mv_svm = delong_test(y_test, y_proba, svm_proba)\n",
    "f, delong_p_rf_svm = delong_test(y_test, rf_proba, svm_proba)\n",
    "\n",
    "print(f\"{delong_p_lr_mv}, {delong_p_lr_rf}, {delong_p_lr_svm}, {delong_p_mv_rf}, {delong_p_mv_svm}, {delong_p_rf_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_train_results_rf.xlsx')\n",
    "svm_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_train_results_svm.xlsx')\n",
    "lr_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_train_results_lr.xlsx')\n",
    "\n",
    "rf_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_results_rf.xlsx')\n",
    "svm_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_results_svm.xlsx')\n",
    "lr_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_results_lr.xlsx')\n",
    "majority_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP4_results_majority.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/df_step3_4_5.csv'\n",
    "df_step5 = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare features and target\n",
    "X5 = df_step5[['\"original_glszm_ZoneEntropy\"', '\"original_shape_LeastAxisLength\"']].values\n",
    "y5 = df_step5['x'].values\n",
    "\n",
    "# Initialize models and preprocessing steps\n",
    "scaler = StandardScaler()\n",
    "oversampler = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=3)\n",
    "randomforest = RandomForestClassifier()\n",
    "svm = SVC(probability=True)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Create pipelines\n",
    "pipeline_rf = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_rf\", randomforest)])\n",
    "pipeline_svm = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_svm\", svm)])\n",
    "pipeline_lr = Pipeline(steps=[(\"oversampler\", oversampler), (\"model_lr\", lr)])\n",
    "\n",
    "# Define hyperparameter grids\n",
    "rf_params = {'model_rf__n_estimators': [25, 50, 75, 100, 125, 150],\n",
    "             'model_rf__min_samples_split': [2, 3],\n",
    "             'model_rf__min_samples_leaf': [1, 2],\n",
    "             'model_rf__max_features': [2]}\n",
    "\n",
    "svm_params = {'model_svm__C': [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "              'model_svm__gamma': [0.5, 0.8, 1, 1.5],\n",
    "              'model_svm__kernel': ['linear'],\n",
    "              'model_svm__probability': [True]}\n",
    "\n",
    "lr_params = {'model_lr__solver': ['lbfgs', 'newton-cg', 'liblinear'],\n",
    "             'model_lr__penalty': ['l2'],\n",
    "             'model_lr__C': [0.1, 0.5, 0.8, 1, 1.25, 2]}\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "num_zeros_list, num_ones_list = [], []\n",
    "rf_train_metrics_list, svm_train_metrics_list, lr_train_metrics_list = [], [], []\n",
    "rf_metrics_list, svm_metrics_list, lr_metrics_list, majority_metrics_list = [], [], [], []\n",
    "rf_all_fpr, rf_all_tpr, svm_all_fpr, svm_all_tpr, lr_all_fpr, lr_all_tpr, majority_all_fpr, majority_all_tpr = [], [], [], [], [], [], [], []\n",
    "\n",
    "# Loop over iterations\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X5, y5, test_size=0.3, stratify=y5, random_state=i)\n",
    "    \n",
    "    # Scale features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Resample training data\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Grid search for each model\n",
    "    rf_gs = GridSearchCV(pipeline_rf, rf_params, scoring='roc_auc')\n",
    "    svm_gs = GridSearchCV(pipeline_svm, svm_params, scoring='roc_auc')\n",
    "    lr_gs = GridSearchCV(pipeline_lr, lr_params, scoring='roc_auc')\n",
    "\n",
    "    rf_gs.fit(X_train_scaled, y_train)\n",
    "    svm_gs.fit(X_train_scaled, y_train)\n",
    "    lr_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Training AUC and hyperparameters\n",
    "    rf_train_auc = rf_gs.best_score_\n",
    "    rf_train_metrics_list.append({'AUC': rf_train_auc, 'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_train_auc = svm_gs.best_score_\n",
    "    svm_train_metrics_list.append({'AUC': svm_train_auc, 'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_train_auc = lr_gs.best_score_\n",
    "    lr_train_metrics_list.append({'AUC': lr_train_auc, 'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    rf_pred = rf_gs.predict(X_test_scaled)\n",
    "    svm_pred = svm_gs.predict(X_test_scaled)\n",
    "    lr_pred = lr_gs.predict(X_test_scaled)\n",
    "\n",
    "    rf_proba = rf_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    svm_proba = svm_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "    lr_proba = lr_gs.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Test set metrics for each model\n",
    "    rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "    svm_auc = roc_auc_score(y_test, svm_proba)\n",
    "    lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "    rf_metrics_list.append({'AUC': rf_auc, 'Accuracy': accuracy_score(y_test, rf_pred), 'Sensitivity': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, rf_pred)[1, 1] / (confusion_matrix(y_test, rf_pred)[1, 1] + confusion_matrix(y_test, rf_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, rf_pred)[0, 0] / (confusion_matrix(y_test, rf_pred)[0, 0] + confusion_matrix(y_test, rf_pred)[1, 0]),\n",
    "                            'Hyperparameters': rf_gs.best_params_})\n",
    "\n",
    "    svm_metrics_list.append({'AUC': svm_auc, 'Accuracy': accuracy_score(y_test, svm_pred), 'Sensitivity': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Specificity': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'PPV': confusion_matrix(y_test, svm_pred)[1, 1] / (confusion_matrix(y_test, svm_pred)[1, 1] + confusion_matrix(y_test, svm_pred)[0, 1]),\n",
    "                             'NPV': confusion_matrix(y_test, svm_pred)[0, 0] / (confusion_matrix(y_test, svm_pred)[0, 0] + confusion_matrix(y_test, svm_pred)[1, 0]),\n",
    "                             'Hyperparameters': svm_gs.best_params_})\n",
    "\n",
    "    lr_metrics_list.append({'AUC': lr_auc, 'Accuracy': accuracy_score(y_test, lr_pred), 'Sensitivity': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Specificity': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'PPV': confusion_matrix(y_test, lr_pred)[1, 1] / (confusion_matrix(y_test, lr_pred)[1, 1] + confusion_matrix(y_test, lr_pred)[0, 1]),\n",
    "                            'NPV': confusion_matrix(y_test, lr_pred)[0, 0] / (confusion_matrix(y_test, lr_pred)[0, 0] + confusion_matrix(y_test, lr_pred)[1, 0]),\n",
    "                            'Hyperparameters': lr_gs.best_params_})\n",
    "\n",
    "    # ROC curve for each model\n",
    "    rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba, drop_intermediate=False)\n",
    "    interp_rf_tpr = np.interp(np.linspace(0, 1, 100), rf_fpr, rf_tpr)\n",
    "    rf_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    rf_all_tpr.append(interp_rf_tpr)\n",
    "\n",
    "    svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_proba, drop_intermediate=False)\n",
    "    interp_svm_tpr = np.interp(np.linspace(0, 1, 100), svm_fpr, svm_tpr)\n",
    "    svm_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    svm_all_tpr.append(interp_svm_tpr)\n",
    "\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_proba, drop_intermediate=False)\n",
    "    interp_lr_tpr = np.interp(np.linspace(0, 1, 100), lr_fpr, lr_tpr)\n",
    "    lr_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    lr_all_tpr.append(interp_lr_tpr)\n",
    "\n",
    "    # Majority Vote model\n",
    "    clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(**{key.split('__')[1]: value for key, value in rf_gs.best_params_.items()})),\n",
    "    ('svm', SVC(**{key.split('__')[1]: value for key, value in svm_gs.best_params_.items()})),\n",
    "    ('lr', LogisticRegression(**{key.split('__')[1]: value for key, value in lr_gs.best_params_.items()}))\n",
    "    ], voting='soft', flatten_transform=True)\n",
    "\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Majority Vote metrics\n",
    "    majority_auc = roc_auc_score(y_test, y_proba)\n",
    "    majority_cm = confusion_matrix(y_test, y_pred)\n",
    "    majority_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    majority_sensitivity = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[1, 0])\n",
    "    majority_specificity = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[0, 1])\n",
    "    majority_ppv = majority_cm[1, 1] / (majority_cm[1, 1] + majority_cm[0, 1])\n",
    "    majority_npv = majority_cm[0, 0] / (majority_cm[0, 0] + majority_cm[1, 0])\n",
    "\n",
    "    majority_metrics_list.append({'AUC': majority_auc, 'Accuracy': majority_accuracy,\n",
    "                                  'Sensitivity': majority_sensitivity, 'Specificity': majority_specificity,\n",
    "                                  'PPV': majority_ppv, 'NPV': majority_npv})\n",
    "\n",
    "    majority_fpr, majority_tpr, _ = roc_curve(y_test, y_proba, drop_intermediate=False)\n",
    "    interp_majority_tpr = np.interp(np.linspace(0, 1, 100), majority_fpr, majority_tpr)\n",
    "    majority_all_fpr.append(np.linspace(0, 1, 100))\n",
    "    majority_all_tpr.append(interp_majority_tpr)\n",
    "\n",
    "    # Store class distribution in each iteration\n",
    "    num_zeros_list.append(np.sum(y_test == 0))\n",
    "    num_ones_list.append(np.sum(y_test == 1))\n",
    "\n",
    "# Create DataFrames for metrics\n",
    "rf_train_metrics_df = pd.DataFrame(rf_train_metrics_list)\n",
    "svm_train_metrics_df = pd.DataFrame(svm_train_metrics_list)\n",
    "lr_train_metrics_df = pd.DataFrame(lr_train_metrics_list)\n",
    "\n",
    "rf_metrics_df_soft = pd.DataFrame(rf_metrics_list)\n",
    "svm_metrics_df_soft = pd.DataFrame(svm_metrics_list)\n",
    "lr_metrics_df_soft = pd.DataFrame(lr_metrics_list)\n",
    "majority_metrics_df_soft = pd.DataFrame(majority_metrics_list)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "rf_mean_fpr = np.mean(rf_all_fpr, axis=0)\n",
    "rf_mean_tpr = np.mean(rf_all_tpr, axis=0)\n",
    "plt.plot(rf_mean_fpr, rf_mean_tpr, label=f'Random Forest AUC = {np.mean(rf_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "\n",
    "svm_mean_fpr = np.mean(svm_all_fpr, axis=0)\n",
    "svm_mean_tpr = np.mean(svm_all_tpr, axis=0)\n",
    "plt.plot(svm_mean_fpr, svm_mean_tpr, label=f'SVM AUC = {np.mean(svm_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "lr_mean_fpr = np.mean(lr_all_fpr, axis=0)\n",
    "lr_mean_tpr = np.mean(lr_all_tpr, axis=0)\n",
    "lr_mean_fpr = np.concatenate([[0], lr_mean_fpr])\n",
    "lr_mean_tpr = np.concatenate([[0], lr_mean_tpr])\n",
    "plt.plot(lr_mean_fpr, lr_mean_tpr, label=f'Logistic Regression AUC = {np.mean(lr_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "majority_mean_fpr = np.mean(majority_all_fpr, axis=0)\n",
    "majority_mean_tpr = np.mean(majority_all_tpr, axis=0)\n",
    "majority_mean_fpr = np.concatenate([[0], majority_mean_fpr])\n",
    "majority_mean_tpr = np.concatenate([[0], majority_mean_tpr])\n",
    "plt.plot(majority_mean_fpr, majority_mean_tpr, label=f'Majority Vote AUC = {np.mean(majority_metrics_df_soft[\"AUC\"]):.3f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for class distribution\n",
    "sanity_check_df = pd.DataFrame({'Num_Zeros': num_zeros_list, 'Num_Ones': num_ones_list})\n",
    "\n",
    "# Print average AUC values for each model in both training and test sets\n",
    "print(f'The average AUC for Random Forest in the training set is: {rf_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the training set is: {svm_train_metrics_df[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the training set is: {lr_train_metrics_df[\"AUC\"].mean()}')\n",
    "print()\n",
    "print(f'The average AUC for Random Forest in the test set is: {rf_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for SVM in the test set is: {svm_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for Logistic Regression in the test set is: {lr_metrics_df_soft[\"AUC\"].mean()}')\n",
    "print(f'The average AUC for the Majority Vote model in the test set is: {majority_metrics_df_soft[\"AUC\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_train_results_rf.xlsx')\n",
    "svm_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_train_results_svm.xlsx')\n",
    "lr_train_metrics_df.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_train_results_lr.xlsx')\n",
    "\n",
    "rf_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_results_rf.xlsx')\n",
    "svm_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_results_svm.xlsx')\n",
    "lr_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_results_lr.xlsx')\n",
    "majority_metrics_df_soft.to_excel('/beegfs/scratch/ric.medicinanucleare/ghezzo.samuele/OSR_STN_CLUSTER/STEP5_results_majority.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1lgVlq_4blIRtn9e_OCytzIYgdfnkwYmP",
     "timestamp": 1706192194848
    },
    {
     "file_id": "1ObdTlWn8j553f7Wh5AASUemmQONGEewB",
     "timestamp": 1706191571233
    },
    {
     "file_id": "1OjM1lAEEI-dwIdbJCVZdrm7HEzs7tkSZ",
     "timestamp": 1706187762576
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d271643f76c404794f654c91a4e202a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d2872510f4e431bbf7f1a9821bb340f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4625810c3b204a21ae5d441f9d0ea4a8",
       "IPY_MODEL_af43ec19f5054e50a44ea962f8190074",
       "IPY_MODEL_94b7becba51f451fb0acc3f0433f5773"
      ],
      "layout": "IPY_MODEL_d4ff65d022864802ab6e37989bfbc7ff"
     }
    },
    "4625810c3b204a21ae5d441f9d0ea4a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95a27a1450b449009cbe702b6130b6d6",
      "placeholder": "",
      "style": "IPY_MODEL_ad7c49aaaa3a4c4589bb526f20a34b14",
      "value": "100%"
     }
    },
    "77f32bf8e5c44f1ba4396eda50df48b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ac5b0d43346470e8311bce70bc003d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b7becba51f451fb0acc3f0433f5773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0c0024ffad9403e9b42b8c7d27c287f",
      "placeholder": "",
      "style": "IPY_MODEL_77f32bf8e5c44f1ba4396eda50df48b4",
      "value": " 3/3 [00:55&lt;00:00, 18.23s/it]"
     }
    },
    "95a27a1450b449009cbe702b6130b6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad7c49aaaa3a4c4589bb526f20a34b14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af43ec19f5054e50a44ea962f8190074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ac5b0d43346470e8311bce70bc003d1",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d271643f76c404794f654c91a4e202a",
      "value": 3
     }
    },
    "b0c0024ffad9403e9b42b8c7d27c287f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ff65d022864802ab6e37989bfbc7ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
